{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Marketing Analytics Project","text":"<p>Customer Retention: Reducing Churn in Subscription-Based Businesses</p> <p></p>"},{"location":"#package-overview","title":"Package Overview","text":"<p>The Marketing Analytics Project addresses high customer churn rates in subscription-based businesses by leveraging advanced analytics, machine learning, and tailored strategies to enhance customer retention. This system provides actionable insights to help businesses grow sustainably and improve profitability.</p>"},{"location":"#high-level-overview","title":"High-Level Overview","text":""},{"location":"#problem","title":"Problem","text":"<p>High churn rates within the first three months lead to: - Loss of long-term revenue potential. - Increased costs for acquiring new customers. - Reduced customer loyalty and engagement.</p>"},{"location":"#solution","title":"Solution","text":"<p>This project tackles churn with: - Advanced Analytics: Insights into customer behavior from feedback, transactions, and usage data. - Machine Learning: Predicting churn likelihood to classify customers as high or low risk. - Tailored Strategies: Implementing data-driven interventions for proactive retention.</p>"},{"location":"#expected-outcomes","title":"Expected Outcomes","text":"<ul> <li>Reduced Churn Rates: Minimize customer loss with targeted retention campaigns.</li> <li>Improved Customer Lifetime Value (CLV): Maximize revenue per customer.</li> <li>Enhanced Insights: Data-driven decision-making to guide effective strategies.</li> </ul>"},{"location":"#contributors","title":"Contributors","text":""},{"location":"#mineh-nazarian","title":"Mineh Nazarian","text":""},{"location":"feedback/","title":"Feedback","text":""},{"location":"feedback/#feedback-processing","title":"Feedback Processing","text":""},{"location":"feedback/#overview","title":"Overview","text":"<p>Feedback data plays a vital role in understanding why customers churn. It captures customer sentiment, experiences, and satisfaction levels.</p>"},{"location":"feedback/#data-flow","title":"Data Flow","text":"<ol> <li>Feedback is generated using synthetic data (via <code>generate_feedback</code> in <code>etl.py</code>).</li> <li>The data is saved as <code>feedback.csv</code> and loaded into the database.</li> <li>Feedback includes:</li> <li>FeedbackID: Unique identifier.</li> <li>CustomerID: Links to the customer table.</li> <li>FeedbackText: Text input from customers.</li> <li>Rating: A numerical rating (1\u20135).</li> </ol>"},{"location":"feedback/#insights-derived","title":"Insights Derived","text":"<ul> <li>Negative feedback (ratings &lt; 3) often correlates with churn.</li> <li>Common issues include poor service quality, high prices, and product dissatisfaction.</li> </ul>"},{"location":"readme/","title":"Marketing Analytics Project","text":"<p>Customer Retention: Reducing Churn in Subscription-Based Businesses</p>"},{"location":"readme/#overview","title":"Overview","text":"<p>High churn rates within the first three months pose a significant challenge for subscription-based businesses. This project focuses on identifying the key drivers of churn, leveraging data analytics to predict customer behavior, and implementing actionable strategies to enhance customer retention. By reducing churn, businesses can achieve sustainable growth, improve customer loyalty, and maximize profitability.</p>"},{"location":"readme/#problem-statement","title":"Problem Statement","text":"<p>Subscription-based businesses often lose a significant number of customers within the initial months. This leads to: - Loss of potential long-term revenue. - Increased costs for acquiring new customers. - Reduced brand loyalty.  </p> <p>The challenge is to understand why customers churn and implement data-driven strategies to reduce churn rates effectively.</p>"},{"location":"readme/#project-objectives","title":"Project Objectives","text":"<ol> <li>Identify churn drivers: Analyze customer demographics, usage behavior, payment history, and feedback to determine factors contributing to churn.  </li> <li>Predict churn: Build predictive models to classify customers into low-risk and high-risk categories.  </li> <li>Enhance retention: Implement and test tailored interventions to improve customer satisfaction and loyalty.  </li> </ol>"},{"location":"readme/#solution-approach","title":"Solution Approach","text":""},{"location":"readme/#1-data-collection","title":"1. Data Collection","text":"<ul> <li>Data sources:  </li> <li>CRM systems for customer demographics and payment history.  </li> <li>Usage analytics for engagement patterns.  </li> <li>Customer feedback surveys for insights into dissatisfaction.  </li> <li>Data preprocessing: Handle missing values, outliers, and ensure data is ready for analysis.</li> </ul>"},{"location":"readme/#2-data-analysis","title":"2. Data Analysis","text":"<ul> <li>Descriptive Analytics: Identify trends and patterns in customer behavior.  </li> <li>Predictive Modeling:  </li> <li>Use machine learning algorithms to predict churn likelihood.  </li> <li>Evaluate models using metrics like accuracy, precision, and recall.  </li> <li>Customer Segmentation: Group customers based on engagement, demographics, and churn risk.</li> </ul>"},{"location":"readme/#3-strategy-development","title":"3. Strategy Development","text":"<ul> <li>Personalized retention strategies, including:  </li> <li>Discounts for at-risk customers.  </li> <li>Tailored engagement campaigns (e.g., targeted emails, in-app messages).  </li> <li>Improved onboarding processes to reduce churn during the early stages.  </li> <li>Pilot strategies with a test group and analyze effectiveness before full implementation.</li> </ul>"},{"location":"readme/#4-success-metrics","title":"4. Success Metrics","text":"<p>Measure the impact of strategies using: - Retention Rate: Percentage of customers retained over a specific period. - Customer Lifetime Value (CLV): Average revenue generated from a customer during their lifetime. - Model Performance: Reduction in churn prediction errors.</p>"},{"location":"readme/#key-features-of-the-project","title":"Key Features of the Project","text":"<ul> <li>Advanced Analytics: Machine learning models for accurate churn prediction.  </li> <li>Data Visualization: Interactive dashboards to track retention metrics.  </li> <li>Actionable Insights: Data-driven recommendations to enhance customer experience.  </li> </ul> <p>Why It Matters? Reducing churn is not just a financial imperative; it builds long-term relationships with customers, strengthens brand reputation, and ensures sustainable business growth. This project demonstrates how businesses can achieve these goals using widely available tools and techniques.  </p>"},{"location":"churn/churn_drivers/","title":"Churn Drivers","text":""},{"location":"churn/churn_drivers/#key-churn-drivers","title":"Key Churn Drivers","text":"<p>Churn drivers are behaviors or actions that increase the likelihood of a customer leaving. In this project, we identified the following key drivers:</p>"},{"location":"churn/churn_drivers/#1-low-usage","title":"1. Low Usage","text":"<ul> <li>Definition: Customers with usage frequency &lt; 5 are considered \"low users\" and are flagged as at risk of churning.</li> <li>Reason: If a customer is not actively using the product, they are less likely to renew their subscription.</li> <li>How to Address: </li> <li>Send usage reminders or feature tutorials.</li> <li>Trigger automated emails encouraging customers to use underutilized features.</li> </ul>"},{"location":"churn/churn_drivers/#2-negative-feedback","title":"2. Negative Feedback","text":"<ul> <li>Definition: Customers who give a feedback rating of less than 3 on a 5-point scale are considered dissatisfied.</li> <li>Reason: Poor experiences or dissatisfaction with a product or service leads to churn.</li> <li>How to Address: </li> <li>Address feedback with personalized customer support.</li> <li>Prioritize resolving issues highlighted in feedback.</li> </ul>"},{"location":"churn/churn_drivers/#3-no-transaction-history","title":"3. No Transaction History","text":"<ul> <li>Definition: Customers who have not made any transactions within a certain period.</li> <li>Reason: No payment activity often indicates disinterest or disengagement.</li> <li>How to Address: </li> <li>Offer time-limited promotions or discounts.</li> <li>Use reminder emails for payment deadlines or plan renewals.</li> </ul>"},{"location":"churn/churn_prediction/","title":"Churn Prediction","text":""},{"location":"churn/churn_prediction/#prediction-logic","title":"Prediction Logic","text":"<p>The churn prediction process relies on a combination of business rules and machine learning models.</p>"},{"location":"churn/churn_prediction/#churn-labeling","title":"Churn Labeling","text":"<ol> <li>Low Usage: Usage frequency &lt; 5 leads to a churn flag.  </li> <li>Negative Feedback: Feedback rating &lt; 3 results in a churn flag.  </li> <li>No Transactions: Customers with no transactions are flagged as potential churn.  </li> </ol> <p>These rules are applied in the ETL process, and the result is stored as a churn_prediction field in the customer table.</p>"},{"location":"churn/churn_prediction/#machine-learning-model","title":"Machine Learning Model","text":"<ol> <li>Model Used: RandomForestClassifier  </li> <li>Features Used:  </li> <li>Age  </li> <li>Location (One-hot encoded)  </li> <li>Usage Frequency  </li> <li> <p>Amount (Transaction data)  </p> </li> <li> <p>Labels:  </p> </li> <li>Churn (1): Indicates a customer has churned.  </li> <li>No Churn (0): Indicates a customer has not churned.  </li> </ol>"},{"location":"churn/churn_prediction/#training-the-model","title":"Training the Model","text":"<ol> <li>Train-Test Split: The data is split into 70% training and 30% testing sets.  </li> <li>Model Training: A RandomForestClassifier is trained on customer data, and the model is saved as <code>final_model.pkl</code>.  </li> <li>Evaluation:  </li> <li>Accuracy, Precision, Recall, and F1 scores are calculated.  </li> <li>The results are stored in <code>model_metrics.txt</code>.  </li> <li>Predictions:  </li> <li>Churn predictions are saved in <code>final_predictions.csv</code>.  </li> <li>Churn probability is also calculated and stored.  </li> </ol>"},{"location":"churn/churn_visualizations/","title":"Churn Visualizations","text":""},{"location":"churn/churn_visualizations/#purpose","title":"Purpose","text":"<p>The visualizations provide a clear view of churn behavior, the factors driving churn, and trends over time. The following visualizations are included:</p>"},{"location":"churn/churn_visualizations/#1-churn-drivers-visualization","title":"1. Churn Drivers Visualization","text":"<p>What it Shows: A bar chart displaying the proportion of customers flagged as churned due to: - Low Usage (Usage frequency &lt; 5) - Negative Feedback (Rating &lt; 3) - No Transactions (No payment activity)  </p> <p>How to Interpret: This visualization highlights which factors contribute most to customer churn. Businesses can prioritize actions to address the most significant drivers.  </p>"},{"location":"churn/churn_visualizations/#2-churn-over-time","title":"2. Churn Over Time","text":"<p>What it Shows: A time-series visualization showing the number of churned customers on a daily, monthly, and yearly basis.  </p> <p>How to Interpret: This visualization highlights when customers are most likely to churn. Businesses can take action by identifying seasonal patterns or critical timeframes for customer retention efforts.  </p>"},{"location":"churn/churn_visualizations/#3-churn-distribution","title":"3. Churn Distribution","text":"<p>What it Shows: A pie chart displaying the proportion of customers who churned versus those who did not churn.  </p> <p>How to Interpret: This visualization gives a snapshot of churn vs. non-churn. If the churn rate is high, targeted retention efforts may be required.  </p>"},{"location":"churn/churn_visualizations/#example-visualizations","title":"Example Visualizations","text":""},{"location":"churn/overview/","title":"Churn Logic Overview","text":""},{"location":"churn/overview/#what-is-churn","title":"What is Churn?","text":"<p>Churn refers to when a customer stops using a company's service or cancels their subscription. It is one of the most important metrics for subscription-based businesses as it directly impacts long-term revenue and customer retention.</p>"},{"location":"churn/overview/#why-is-churn-important","title":"Why is Churn Important?","text":"<ul> <li>Revenue Loss: Losing a customer means losing future revenue from that customer.</li> <li>Acquisition Costs: Acquiring new customers is often more expensive than retaining existing ones.</li> <li>Brand Loyalty: High churn can negatively affect brand perception.</li> </ul>"},{"location":"churn/overview/#churn-prediction-approach","title":"Churn Prediction Approach","text":"<ol> <li>Data Sources: Customer demographics, usage analytics, transaction history, and customer feedback.  </li> <li>Churn Drivers: Identifying behaviors and signals that indicate a high likelihood of churn.  </li> <li>Churn Prediction Model: Machine learning models are used to predict customer churn and identify high-risk customers.  </li> <li>Retention Strategies: Personalized interventions are deployed to retain at-risk customers.</li> </ol> <p>This documentation will guide you through the logic, drivers, prediction methods, and visualizations used to analyze and prevent churn.</p>"},{"location":"services/etl/","title":"ETL","text":""},{"location":"services/etl/#main-etl-process-etlpy","title":"Main ETL Process (<code>etl.py</code>)","text":""},{"location":"services/etl/#loading-modules-and-packages","title":"Loading modules and packages","text":"<p>from models import *  # Import all models from database import engine, SessionLocal from data_generator import (     generate_customer,     generate_usage,     generate_transaction,     generate_feedback, ) import pandas as pd from loguru import logger import random import glob from os import path import os from sqlalchemy import text from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report</p>"},{"location":"services/etl/#declaring-constants","title":"Declaring Constants","text":"<p>NUMBER_OF_CUSTOMERS = 2000 NUMBER_OF_USAGE_RECORDS = 5000 NUMBER_OF_TRANSACTIONS = 3000 NUMBER_OF_FEEDBACK_RECORDS = 1000</p>"},{"location":"services/etl/#ensure-data-folder-exists","title":"Ensure data folder exists","text":"<p>DATA_FOLDER = \"data/\" os.makedirs(DATA_FOLDER, exist_ok=True)</p>"},{"location":"services/etl/#generating-customer-data","title":"Generating Customer Data","text":"<p>customers = pd.DataFrame(     [generate_customer(customer_id) for customer_id in range(NUMBER_OF_CUSTOMERS)] ) logger.info(\"Customer Data\") logger.info(customers.head(1)) customers.to_csv(f\"{DATA_FOLDER}customers.csv\", index=False) logger.info(f\"Customer Data saved to CSV: {customers.shape}\")</p>"},{"location":"services/etl/#generating-usage-data","title":"Generating Usage Data","text":"<p>usage = pd.DataFrame(     [         generate_usage(usage_id, random.randint(1, NUMBER_OF_CUSTOMERS))         for usage_id in range(NUMBER_OF_USAGE_RECORDS)     ] ) logger.info(\"Usage Data\") logger.info(usage.head(1)) usage.to_csv(f\"{DATA_FOLDER}usage.csv\", index=False) logger.info(f\"Usage Data saved to CSV: {usage.shape}\")</p>"},{"location":"services/etl/#generating-transaction-data","title":"Generating Transaction Data","text":"<p>transactions = pd.DataFrame(     [         generate_transaction(transaction_id, random.randint(1, NUMBER_OF_CUSTOMERS))         for transaction_id in range(NUMBER_OF_TRANSACTIONS)     ] ) logger.info(\"Transaction Data\") logger.info(transactions.head(1)) transactions.to_csv(f\"{DATA_FOLDER}transactions.csv\", index=False) logger.info(f\"Transaction Data saved to CSV: {transactions.shape}\")</p>"},{"location":"services/etl/#generating-feedback-data","title":"Generating Feedback Data","text":"<p>feedback = pd.DataFrame(     [         generate_feedback(feedback_id, random.randint(1, NUMBER_OF_CUSTOMERS))         for feedback_id in range(NUMBER_OF_FEEDBACK_RECORDS)     ] ) logger.info(\"Feedback Data\") logger.info(feedback.head(1)) feedback.to_csv(f\"{DATA_FOLDER}feedback.csv\", index=False) logger.info(f\"Feedback Data saved to CSV: {feedback.shape}\")</p>"},{"location":"services/etl/#load-csv-to-database-table-with-duplicate-handling","title":"Load CSV to Database Table with Duplicate Handling","text":"<p>def load_csv_to_table(table_name, csv_path):     \"\"\"     Load data from a CSV file into a database table.     Skips rows with duplicate primary keys using ON CONFLICT DO NOTHING.</p> <pre><code>Args:\n    table_name (str): Name of the database table.\n    csv_path (str): Path to the CSV file containing data.\n\"\"\"\ntry:\n    # Load CSV into DataFrame\n    df = pd.read_csv(csv_path)\n\n    # Use SQLAlchemy to insert rows with conflict handling\n    with engine.connect() as connection:\n        for _, row in df.iterrows():\n            # Build INSERT query with ON CONFLICT DO NOTHING\n            query = text(f\"\"\"\n                INSERT INTO {table_name} ({', '.join(df.columns)})\n                VALUES ({', '.join([':{}'.format(col) for col in df.columns])})\n                ON CONFLICT DO NOTHING;\n            \"\"\")\n            connection.execute(query, row.to_dict())\n    logger.info(f\"Loaded {table_name} into the database (skipping duplicates).\")\nexcept Exception as e:\n    logger.error(f\"Failed to load {table_name}: {e}\")\n</code></pre>"},{"location":"services/etl/#fetch-combined-data-for-predictions","title":"Fetch Combined Data for Predictions","text":"<p>def fetch_data_for_predictions():     \"\"\"     Fetch and combine data from the database for training and prediction purposes.</p> <pre><code>Returns:\n    DataFrame: Combined customer data.\n\"\"\"\nsession = SessionLocal()\ntry:\n    customers = session.query(Customer).all()\n    usage = session.query(Usage).all()\n    transactions = session.query(Transaction).all()\n\n    # Convert data into DataFrames\n    customers_df = pd.DataFrame([{\n        'customer_id': c.customer_id,\n        'age': c.age,\n        'location': c.location\n    } for c in customers])\n\n    usage_df = pd.DataFrame([{\n        'customer_id': u.customer_id,\n        'usage_frequency': u.usage_frequency\n    } for u in usage])\n\n    transactions_df = pd.DataFrame([{\n        'customer_id': t.customer_id,\n        'amount': t.amount\n    } for t in transactions])\n\n    # Merge data into one DataFrame\n    data = customers_df.merge(usage_df, on=\"customer_id\", how=\"left\")\n    data = data.merge(transactions_df, on=\"customer_id\", how=\"left\")\n    return data\nfinally:\n    session.close()\n</code></pre>"},{"location":"services/etl/#train-model-and-predict","title":"Train Model and Predict","text":"<p>def train_and_predict(data):     \"\"\"     Train a machine learning model and predict churn probabilities.</p> <pre><code>Args:\n    data (DataFrame): Combined customer data.\n\nReturns:\n    DataFrame: Updated DataFrame with predictions and probabilities.\n\"\"\"\ndata['churn'] = (data['usage_frequency'] &lt; 5).astype(int)\n\n# Features and target\nfeatures = ['age', 'usage_frequency', 'amount']\nX = data[features].fillna(0)\ny = data['churn']\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\n# Train the model\nmodel = RandomForestClassifier(random_state=42)\nmodel.fit(X_train, y_train)\n\n# Evaluate the model\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\n\n# Predict probabilities\ndata['predicted_churn'] = model.predict(X)\ndata['churn_probability'] = model.predict_proba(X)[:, 1]\nreturn data\n</code></pre>"},{"location":"services/etl/#populate-results-table","title":"Populate Results Table","text":"<p>def populate_results_table(data):     \"\"\"     Populate the results table with prediction data.</p> <pre><code>Args:\n    data (DataFrame): DataFrame containing prediction results.\n\"\"\"\nsession = SessionLocal()\ntry:\n    for _, row in data.iterrows():\n        result = Result(\n            customer_id=row['customer_id'],\n            prediction=\"Churn\" if row['predicted_churn'] == 1 else \"No Churn\",\n            probability=row['churn_probability'],\n            created_at=pd.Timestamp.now()\n        )\n        session.add(result)\n    session.commit()\n    logger.info(\"Results table populated.\")\nfinally:\n    session.close()\n</code></pre>"},{"location":"services/etl/#main-etl-process","title":"Main ETL Process","text":"<p>if name == \"main\":     logger.info(\"Starting ETL process...\")</p> <pre><code># Load data into database\nfolder_path = f\"{DATA_FOLDER}*.csv\"\nfiles = glob.glob(folder_path)\nfor file_path in files:\n    table_name = path.splitext(path.basename(file_path))[0]\n    load_csv_to_table(table_name, file_path)\n\n# Fetch data for predictions\ndata_for_predictions = fetch_data_for_predictions()\n\n# Train model and generate predictions\ndata_with_predictions = train_and_predict(data_for_predictions)\n\n# Populate results table\npopulate_results_table(data_with_predictions)\n\nlogger.info(\"ETL process completed.\")\n</code></pre>"},{"location":"services/etl/#data-generation-data_generatorpy","title":"Data Generation (<code>data_generator.py</code>)","text":"<p>from faker import Faker import pandas as pd import random from datetime import datetime</p>"},{"location":"services/etl/#initialize-faker","title":"Initialize Faker","text":"<p>fake = Faker()</p> <p>def generate_customer(customer_id):     \"\"\"     Generate a single customer record.</p> <pre><code>Args:\n    customer_id (int): Unique identifier for the customer.\n\nReturns:\n    dict: A dictionary representing the customer's details.\n        - customer_id (int): Customer's unique ID.\n        - name (str): Full name of the customer.\n        - age (int): Age of the customer (18-80).\n        - gender (str): Gender of the customer.\n        - location (str): City of residence.\n\"\"\"\nreturn {\n    \"customer_id\": customer_id,\n    \"name\": fake.name(),\n    \"age\": random.randint(18, 80),\n    \"gender\": random.choice([\"Male\", \"Female\", \"Other\"]),\n    \"location\": fake.city()\n}\n</code></pre> <p>def generate_usage(usage_id, customer_id):     \"\"\"     Generate a single usage record.</p> <pre><code>Args:\n    usage_id (int): Unique identifier for the usage record.\n    customer_id (int): Unique identifier for the associated customer.\n\nReturns:\n    dict: A dictionary representing the usage record.\n        - usage_id (int): Usage record's unique ID.\n        - customer_id (int): Customer's unique ID.\n        - feature_name (str): Name of the feature used.\n        - usage_frequency (int): Number of times the feature was used (1-500).\n        - last_used_date (date): The last date the feature was used (up to 1 year ago).\n\"\"\"\nreturn {\n    \"usage_id\": usage_id,\n    \"customer_id\": customer_id,\n    \"feature_name\": random.choice([\"Feature A\", \"Feature B\", \"Feature C\", \"Feature D\"]),\n    \"usage_frequency\": random.randint(1, 500),\n    \"last_used_date\": fake.date_between(start_date='-1y', end_date='today')\n}\n</code></pre> <p>def generate_transaction(transaction_id, customer_id):     \"\"\"     Generate a single transaction record.</p> <pre><code>Args:\n    transaction_id (int): Unique identifier for the transaction record.\n    customer_id (int): Unique identifier for the associated customer.\n\nReturns:\n    dict: A dictionary representing the transaction record.\n        - transaction_id (int): Transaction's unique ID.\n        - customer_id (int): Customer's unique ID.\n        - payment_date (date): The date of the payment (up to 1 year ago).\n        - amount (float): The amount paid for the plan with minor price variations.\n        - plan_type (str): Type of plan purchased (Basic, Premium, Enterprise).\n\"\"\"\nplan_types = [\"Basic\", \"Premium\", \"Enterprise\"]\nplan_prices = {\"Basic\": 9.99, \"Premium\": 19.99, \"Enterprise\": 49.99}\nplan_type = random.choice(plan_types)\namount = plan_prices[plan_type] + round(random.uniform(-2.0, 2.0), 2)\n\nreturn {\n    \"transaction_id\": transaction_id,\n    \"customer_id\": customer_id,\n    \"payment_date\": fake.date_between(start_date='-1y', end_date='today'),\n    \"amount\": amount,\n    \"plan_type\": plan_type\n}\n</code></pre> <p>def generate_feedback(feedback_id, customer_id):     \"\"\"     Generate a single feedback record.</p> <pre><code>Args:\n    feedback_id (int): Unique identifier for the feedback record.\n    customer_id (int): Unique identifier for the associated customer.\n\nReturns:\n    dict: A dictionary representing the feedback record.\n        - feedback_id (int): Feedback record's unique ID.\n        - customer_id (int): Customer's unique ID.\n        - feedback_text (str): Randomly generated feedback text.\n        - rating (int): Rating given by the customer (1-5).\n\"\"\"\nreturn {\n    \"feedback_id\": feedback_id,\n    \"customer_id\": customer_id,\n    \"feedback_text\": fake.sentence(),\n    \"rating\": random.randint(1, 5)\n}\n</code></pre>"},{"location":"services/etl/#machine-learning-model-data_science_modelpy","title":"Machine Learning Model (<code>data_science_model.py</code>)","text":"<p>from sqlalchemy.orm import sessionmaker from database import engine from models import Customer, Usage, Transaction, Feedback import pandas as pd from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import train_test_split from sklearn.metrics import classification_report import joblib</p>"},{"location":"services/etl/#establish-database-session","title":"Establish database session","text":"<p>Session = sessionmaker(bind=engine) session = Session()</p> <p>def fetch_and_prepare_data():     customers = session.query(Customer).all()     customers_df = pd.DataFrame([{         'customer_id': c.customer_id,         'age': c.age,         'gender': c.gender,         'location': c.location,         'churn_prediction': c.churn_prediction     } for c in customers])</p> <pre><code>usage = session.query(Usage).all()\nusage_df = pd.DataFrame([{\n    'customer_id': u.customer_id,\n    'usage_frequency': u.usage_frequency,\n    'last_used_date': u.last_used_date\n} for u in usage])\n\ntransactions = session.query(Transaction).all()\ntransactions_df = pd.DataFrame([{\n    'customer_id': t.customer_id,\n    'amount': t.amount,\n    'plan_type': t.plan_type\n} for t in transactions])\n\ndata = customers_df.merge(usage_df, on=\"customer_id\", how=\"left\")\ndata = data.merge(transactions_df, on=\"customer_id\", how=\"left\")\n\ndata['plan_type'] = data['plan_type'].fillna('Unknown')\ndata['amount'] = data['amount'].fillna(0)\ndata['usage_frequency'] = data['usage_frequency'].fillna(0)\n\ndata = pd.get_dummies(data, columns=['gender', 'plan_type', 'location'], drop_first=True)\nreturn data\n</code></pre> <p>def train_model(data):     features = [col for col in data.columns if col not in ['customer_id', 'churn_prediction']]     target = 'churn_prediction'</p> <pre><code>X = data[features]\ny = data[target]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nmodel = RandomForestClassifier(random_state=42, n_estimators=200, max_depth=10)\nmodel.fit(X_train, y_train)\n\ny_pred = model.predict(X_test)\nreport = classification_report(y_test, y_pred)\nprint(\"Model Evaluation:\")\nprint(report)\n\nwith open(\"model_metrics.txt\", \"w\") as f:\n    f.write(\"Model Evaluation Metrics:\\n\")\n    f.write(report)\n\ndata['predicted_churn'] = model.predict(X)\ndata['churn_probability'] = model.predict_proba(X)[:, 1]\nreturn model, data\n</code></pre> <p>def update_predictions_in_database(data):     try:         print(\"Updating churn predictions in the database...\")         for _, row in data.iterrows():             # Fetch the customer from the database             customer = session.query(Customer).filter_by(customer_id=row['customer_id']).first()</p> <pre><code>        if customer:\n            # Update churn_prediction field\n            customer.churn_prediction = int(row['predicted_churn'])\n        else:\n            print(f\"Customer with ID {row['customer_id']} not found in the database.\")\n\n    # Commit all updates\n    session.commit()\n    print(\"Churn predictions successfully updated in the database.\")\nexcept Exception as e:\n    # Rollback in case of any failure\n    session.rollback()\n    print(f\"Error updating database: {e}\")\n</code></pre> <p>def save_model(model, filename=\"final_model.pkl\"):     joblib.dump(model, filename)     print(f\"Model saved to {filename}.\")</p> <p>def save_predictions_to_csv(data, filename=\"final_predictions.csv\"):     final_output = data[['customer_id', 'predicted_churn', 'churn_probability']]     final_output.to_csv(filename, index=False)     print(f\"Predictions saved to {filename}.\")</p> <p>if name == \"main\":     print(\"Fetching and preparing data...\")     data = fetch_and_prepare_data()</p> <pre><code>print(\"Training the model...\")\nmodel, data_with_predictions = train_model(data)\n\nprint(\"Updating predictions in the database...\")\nupdate_predictions_in_database(data_with_predictions)\n\nprint(\"Saving the model...\")\nsave_model(model)\n\nprint(\"Saving predictions to a CSV file...\")\nsave_predictions_to_csv(data_with_predictions)\n\nprint(\"Model training and prediction process completed successfully!\")\n</code></pre>"},{"location":"services/pgadmin/","title":"PgAdmin","text":"<p>db:     container_name: postgresql_db     image: postgres     restart: always     ports:       - 5432:5432     environment:        - POSTGRES_USER=${DB_USER}       - POSTGRES_PASSWORD=${DB_PASSWORD}       - POSTGRES_DB=${DB_NAME}     healthcheck:         test: [\"CMD-SHELL\", \"pg_isready -U postgres\"]  # Healthcheck for PostgreSQL         interval: 60s         timeout: 10s         retries: 5     volumes:       - ./postgres_data:/var/lib/postgresql/data # Persisting data</p> <p>pgadmin:     container_name: pgadmin     image: dpage/pgadmin4     environment:       - PGADMIN_DEFAULT_EMAIL=${PGADMIN_EMAIL}       - PGADMIN_DEFAULT_PASSWORD=${PGADMIN_PASSWORD}       - PGADMIN_CONFIG_WTF_CSRF_ENABLED=False  # Disable CSRF for local development     ports:       - 5050:80 # for local browser     volumes:       - ./pgadmin_data:/var/lib/pgadmin  # Persisting pgAdmin configuration and sessions     depends_on:        - db</p> <p>etl:     container_name: etl     build:       context: ./etl       dockerfile: Dockerfile     ports:       - 3000:3000     volumes:         - ./etl:/etl     depends_on:        db:         condition: service_healthy     healthcheck:       test: \"exit 0\"</p>"},{"location":"services/postgres/","title":"PostgreSQL","text":""},{"location":"services/postgres/#database-models-modelspy","title":"Database Models (<code>models.py</code>)","text":"<p>from sqlalchemy import Column, Integer, String, ForeignKey, Float, DateTime from sqlalchemy.orm import relationship from database import Base, engine import datetime</p>"},{"location":"services/postgres/#customer-model","title":"Customer Model","text":"<p>class Customer(Base):     tablename = 'customers'     customer_id = Column(Integer, primary_key=True)     name = Column(String)     age = Column(Integer)     gender = Column(String)     location = Column(String)     churn_prediction = Column(Integer, nullable=True)     transactions = relationship(\"Transaction\", back_populates=\"customer\")     usage = relationship(\"Usage\", back_populates=\"customer\")     feedback = relationship(\"Feedback\", back_populates=\"customer\")     results = relationship(\"Result\", back_populates=\"customer\")</p>"},{"location":"services/postgres/#usage-model","title":"Usage Model","text":"<p>class Usage(Base):     tablename = 'usage'     usage_id = Column(Integer, primary_key=True)     feature_name = Column(String)     usage_frequency = Column(Integer)     payment_date = Column(DateTime, default=datetime.datetime.utcnow)     last_used_date = Column(DateTime, default=datetime.datetime.utcnow)     customer_id = Column(Integer, ForeignKey('customers.customer_id'))     customer = relationship(\"Customer\", back_populates=\"usage\")</p>"},{"location":"services/postgres/#transaction-model","title":"Transaction Model","text":"<p>class Transaction(Base):     tablename = 'transactions'     transaction_id = Column(Integer, primary_key=True)     amount = Column(Float)     plan_type = Column(String)     payment_date = Column(DateTime, default=datetime.datetime.utcnow)     last_used_date = Column(DateTime, default=datetime.datetime.utcnow)     customer_id = Column(Integer, ForeignKey('customers.customer_id'))     customer = relationship(\"Customer\", back_populates=\"transactions\")</p>"},{"location":"services/postgres/#feedback-model","title":"Feedback Model","text":"<p>class Feedback(Base):     tablename = 'feedback'     feedback_id = Column(Integer, primary_key=True)     feedback_text = Column(String)     rating = Column(Integer)     customer_id = Column(Integer, ForeignKey('customers.customer_id'))     customer = relationship(\"Customer\", back_populates=\"feedback\")</p>"},{"location":"services/postgres/#results-model","title":"Results Model","text":"<p>class Result(Base):     tablename = 'results'     result_id = Column(Integer, primary_key=True, autoincrement=True)     customer_id = Column(Integer, ForeignKey('customers.customer_id'), nullable=False)     prediction = Column(String, nullable=False)     probability = Column(Float, nullable=False)     created_at = Column(DateTime, default=datetime.datetime.utcnow)     customer = relationship(\"Customer\", back_populates=\"results\")</p>"},{"location":"services/postgres/#create-all-tables","title":"Create all tables","text":"<p>if name == \"main\":     Base.metadata.create_all(engine)</p>"},{"location":"services/postgres/#database-connection-databasepy","title":"Database Connection (<code>database.py</code>)","text":"<p>\"\"\" Database Configuration</p> <p>This module sets up the database connection, engine, and session management using SQLAlchemy. It loads configuration from environment variables defined in a <code>.env</code> file. \"\"\"</p> <p>import sqlalchemy as sql import sqlalchemy.ext.declarative as declarative import sqlalchemy.orm as orm from dotenv import load_dotenv import os</p> <p>def get_db():     \"\"\"     Provides a database session for interacting with the database.</p> <pre><code>This function is used to yield a SQLAlchemy session object (`SessionLocal`) \nfor performing database operations. The session is automatically closed \nafter use to prevent connection leaks.\n\nYields:\n    SessionLocal: A SQLAlchemy session object.\n\"\"\"\ndb = SessionLocal()\ntry:\n    yield db\nfinally:\n    db.close()\n</code></pre>"},{"location":"services/postgres/#load-environment-variables-from-the-env-file","title":"Load environment variables from the <code>.env</code> file","text":"<p>load_dotenv(\".env\")</p>"},{"location":"services/postgres/#get-the-database-url-from-environment-variables","title":"Get the database URL from environment variables","text":"<p>DATABASE_URL = os.environ.get(\"DATABASE_URL\") \"\"\" str: The database connection URL. This value is loaded from the <code>.env</code> file and is used to configure the SQLAlchemy engine. Example format: <code>postgresql+psycopg2://user:password@host:port/database</code> \"\"\"</p>"},{"location":"services/postgres/#create-the-sqlalchemy-engine","title":"Create the SQLAlchemy engine","text":"<p>engine = sql.create_engine(DATABASE_URL) \"\"\" Engine: SQLAlchemy engine object used to manage the connection pool and  execute SQL statements. Configured using the <code>DATABASE_URL</code>. \"\"\"</p>"},{"location":"services/postgres/#base-class-for-declarative-models","title":"Base class for declarative models","text":"<p>Base = declarative.declarative_base() \"\"\" DeclarativeMeta: Base class for all ORM models. All models should inherit from this to define database tables. \"\"\"</p>"},{"location":"services/postgres/#sessionlocal-for-database-operations","title":"SessionLocal for database operations","text":"<p>SessionLocal = orm.sessionmaker(autocommit=False, autoflush=False, bind=engine) \"\"\" Session: Configured sessionmaker object for creating session instances. Sessions are used to interact with the database and manage transactions. \"\"\"</p>"},{"location":"services/postgres/#test-the-database-connection-when-run-directly","title":"Test the database connection when run directly","text":"<p>if name == \"main\":     \"\"\"     When this script is executed directly, it attempts to establish a connection      to the database and outputs the status. This is useful for verifying the      database configuration.     \"\"\"     try:         with engine.connect() as connection:             print(\"Connected to the new database successfully!\")     except Exception as e:         print(f\"Failed to connect to the database: {e}\")</p>"}]}